---
title: "linear_regreesion_model"
format: html
editor: visual
editor_options: 
  chunk_output_type: console
---

## linear regression isnt appropriate 
```{r}
library(tidyverse)
heart_data <- read_csv("https://www4.stat.ncsu.edu/online/datasets/heart.csv") |>
  filter(RestingBP > 0) #remove one value
heart_data |> select(HeartDisease, everything()) #Cholesterol has many values set to 0 so we ignore that
```

binary 1 -> has heart disease 
binary 0 -> does not have heart disease
were going to try to model (P(Y=1| x variables) = probability of heart disease given some predictors 

summarize heart disease prevalence 
```{r}
heart_data |>
  group_by(HeartDisease) |> 
  summarize(count = n())
```
p-hat = 507/917 


```{r}
heart_data |>
  group_by(HeartDisease) |>
  summarize(mean_Age = mean(Age),
            mean_RestingBP  = mean(RestingBP))
```

lets try to use age as predictor 
```{r}
ggplot(heart_data, aes(x = Age, y = HeartDisease, color = RestingBP)) +
         geom_point() +
  geom_smooth(method = "lm")
```
looking at P(Y=1|x) = B-hat0 + B-hat1x
probability of having heart disease given x which in this case is age 

```{r}
ggplot(heart_data, aes(x = Age, y = HeartDisease, color = RestingBP)) +
         geom_jitter() +
  geom_smooth(method = "lm")
```


obtain proportion with heart disease for different age groups 
```{r}
Age_x <- seq(from = min(heart_data$Age), to = max(heart_data$Age), length = 20)
heart_data_grouped <- heart_data |>
  mutate(Age_groups = cut(Age, breaks = Age_x)) |>
  group_by(Age_groups) |>
  summarize(HeartDisease_mean = mean(HeartDisease), counts = n())
heart_data_grouped
```

can add the different age buckets into our plot 
```{r}
ggplot(data = heart_data, aes(x = Age, y = HeartDisease)) +
  geom_jitter(aes(color = RestingBP)) +
  geom_point(data = heart_data_grouped, aes(x = Age_x, y = HeartDisease_mean, size = counts)) +
  geom_smooth(method = "lm", color = "Green")
```

## Logistic regression fit 
Using Age to predict heart disease via a logistic regression model 
it is a sigmoid function that looks linear close up


first, well do a training/test split via initial_split()
lets also create our CV splits on the training data 
```{r}
library(tidymodels)
set.seed(3557)
heart_data <- heart_data |> mutate(HeartDisease = factor(HeartDisease))
heart_split <- initial_split(heart_data, prop = 0.8)
heart_train <- training(heart_split)
heart_test <- testing(heart_split)
heart_CV_folds <- vfold_cv(heart_train, 10)
```


Next, we'll set up our recipes for the data, standardizing these numeric variables

Model 1: Age and Sex as predictors
Model 2: Age, Sex, ChestPainType, RestingBP and RestingECG as predictors
Model 3: Age, Sex, ChestPainType, RestingBP, RestingECG, MaxHR, and ExerciseAngina
```{r}
LR1_rec <- recipe(HeartDisease ~ Age + Sex, 
                  data = heart_train) |>
  step_normalize(Age) |>
  step_dummy(Sex)
LR2_rec <- recipe(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + RestingECG, 
                  data = heart_train) |>
  step_normalize(all_numeric(), -HeartDisease) |>
  step_dummy(Sex, ChestPainType, RestingECG)
LR3_rec <- recipe(HeartDisease ~ Age + Sex + ChestPainType + RestingBP + RestingECG + MaxHR + ExerciseAngina, 
                  data = heart_train) |>
  step_normalize(all_numeric(), -HeartDisease) |>
  step_dummy(Sex, ChestPainType, RestingECG, ExerciseAngina)
LR3_rec |> prep(heart_train) |> bake(heart_train) |> colnames()
```

Now set up our model type and engine
```{r}
LR_spec <- logistic_reg() |>
  set_engine("glm")
```

Create our workflows
```{r}
LR1_wkf <- workflow() |>
  add_recipe(LR1_rec) |>
  add_model(LR_spec)
LR2_wkf <- workflow() |>
  add_recipe(LR2_rec) |>
  add_model(LR_spec)
LR3_wkf <- workflow() |>
  add_recipe(LR3_rec) |>
  add_model(LR_spec)
```

fit our CV folds
```{r}
LR1_fit <- LR1_wkf |>
  fit_resamples(heart_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
LR2_fit <- LR2_wkf |>
  fit_resamples(heart_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
LR3_fit <- LR3_wkf |>
  fit_resamples(heart_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
```

Collect our metrics and see which model did the best!
```{r}
rbind(LR1_fit |> collect_metrics(),
      LR2_fit |> collect_metrics(),
      LR3_fit |> collect_metrics()) |>
  mutate(Model = c("Model1", "Model1", "Model2", "Model2", "Model3", "Model3")) |>
  select(Model, everything())
```

```{r}
#compare to proportion of 1's in training data
mean(heart_train$HeartDisease == "1")
```

Find the confusion matrix for our best model on the training set
```{r}
LR_train_fit <- LR3_wkf |>
  fit(heart_train)
conf_mat(heart_train |> mutate(estimate = LR_train_fit |> predict(heart_train) |> pull()), #data
         HeartDisease, #truth
         estimate) #estimate from model
```

Grab our 'best' model and test it on the test set
```{r}
LR3_wkf |>
  last_fit(heart_split, metrics = metric_set(accuracy, mn_log_loss)) |>
  collect_metrics()
```

```{r}
conf_mat(heart_test |> mutate(estimate = LR_train_fit |> predict(heart_test) |> pull()), HeartDisease, estimate)
```

Suppose we like this model the best overall, we'd fit it to the entire data set
```{r}
final_model <- LR3_wkf |>
  fit(heart_data)
tidy(final_model)
```

**Recap**
Logistic regression often a reasonable model for a binary response

Uses a sigmoid function to ensure valid predictions

Can predict success or failure using estimated probabilities

Usually predict success if probability 
>
 0.5

Common metrics for classification are accuracy and log-loss